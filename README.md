# Finetuning de SAM2 para Segmentaci√≥n M√©dica ‚úÖ ACTUALIZADO

## üîß CORRECCIONES APLICADAS

### ‚úÖ Problemas Solucionados:
1. **TypeError ReduceLROnPlateau**: Removido argumento `verbose` no soportado
2. **Modelo actualizado**: Migrado de SAM a SAM2 oficial
3. **Imports corregidos**: Usando `Sam2Model` y `Sam2Processor` de transformers
4. **Modelo por defecto**: Cambiado a `facebook/sam2-hiera-base-plus`

### üéØ Modelos SAM2 Disponibles:
- `facebook/sam2-hiera-tiny` (m√°s r√°pido, menos preciso)
- `facebook/sam2-hiera-small` (balance)
- `facebook/sam2-hiera-base-plus` (recomendado, por defecto)
- `facebook/sam2-hiera-large` (mejor rendimiento, m√°s recursos)

---

Este proyecto implementa tres m√©todos de finetuning para SAM2 (Segment Anything Model 2) aplicado a segmentaci√≥n m√©dica usando datasets en formato COCO.

## üéØ M√©todos Implementados

1. **Finetuning Cl√°sico**: Entrena todos los par√°metros del modelo
2. **LoRA (Low-Rank Adaptation)**: Entrena solo adaptadores de bajo rango
3. **QLoRA (Quantized LoRA)**: Combina quantizaci√≥n 4-bit con LoRA para m√°xima eficiencia

## üìÅ Estructura del Proyecto

```
Finetuning SAM2/
‚îú‚îÄ‚îÄ utils.py                 # Utilidades comunes (dataset, m√©tricas, visualizaci√≥n)
‚îú‚îÄ‚îÄ finetune_classic.py      # Finetuning cl√°sico
‚îú‚îÄ‚îÄ finetune_lora.py         # Finetuning con LoRA
‚îú‚îÄ‚îÄ finetune_qlora.py        # Finetuning con QLoRA
‚îú‚îÄ‚îÄ main.py                  # Script principal para ejecutar todos los m√©todos
‚îú‚îÄ‚îÄ inference.py             # Script de inferencia y evaluaci√≥n
‚îú‚îÄ‚îÄ README.md                # Este archivo
‚îî‚îÄ‚îÄ data/                    # Datasets
    ‚îú‚îÄ‚îÄ Cataract COCO Segmentation/
    ‚îÇ   ‚îú‚îÄ‚îÄ train/
    ‚îÇ   ‚îú‚îÄ‚îÄ valid/
    ‚îÇ   ‚îî‚îÄ‚îÄ test/
    ‚îî‚îÄ‚îÄ Diabetic-Retinopathy COCO Segmentation/
        ‚îú‚îÄ‚îÄ train/
        ‚îú‚îÄ‚îÄ valid/
        ‚îî‚îÄ‚îÄ test/
```

## üöÄ Instalaci√≥n

### Requisitos
- Python 3.10+
- CUDA (recomendado para GPU)
- 8GB+ RAM
- 4GB+ VRAM (GPU)

### Instalaci√≥n de dependencias
Las dependencias se instalan autom√°ticamente:
- torch
- transformers
- datasets
- peft
- pycocotools
- opencv-python
- bitsandbytes
- accelerate

## üìä Datasets

El proyecto usa dos datasets m√©dicos en formato COCO:

1. **Cataract COCO Segmentation**: Segmentaci√≥n de cataratas
2. **Diabetic-Retinopathy COCO Segmentation**: Segmentaci√≥n de retinopat√≠a diab√©tica

Cada dataset debe tener la estructura:
```
Dataset/
‚îú‚îÄ‚îÄ train/
‚îÇ   ‚îú‚îÄ‚îÄ _annotations.coco.json
‚îÇ   ‚îî‚îÄ‚îÄ *.jpg
‚îú‚îÄ‚îÄ valid/
‚îÇ   ‚îú‚îÄ‚îÄ _annotations.coco.json
‚îÇ   ‚îî‚îÄ‚îÄ *.jpg
‚îî‚îÄ‚îÄ test/
    ‚îú‚îÄ‚îÄ _annotations.coco.json
    ‚îî‚îÄ‚îÄ *.jpg
```

## üèÉ‚Äç‚ôÇÔ∏è Uso R√°pido

### 1. Ejecutar todos los m√©todos
```bash
python main.py --cataract_dir "data/Cataract COCO Segmentation" \
               --retinopathy_dir "data/Diabetic-Retinopathy COCO Segmentation" \
               --run_all
```

### 2. Ejecutar m√©todo espec√≠fico
```bash
# Solo finetuning cl√°sico
python main.py --cataract_dir "data/Cataract COCO Segmentation" \
               --retinopathy_dir "data/Diabetic-Retinopathy COCO Segmentation" \
               --run_classic

# Solo LoRA
python main.py --cataract_dir "data/Cataract COCO Segmentation" \
               --retinopathy_dir "data/Diabetic-Retinopathy COCO Segmentation" \
               --run_lora

# Solo QLoRA
python main.py --cataract_dir "data/Cataract COCO Segmentation" \
               --retinopathy_dir "data/Diabetic-Retinopathy COCO Segmentation" \
               --run_qlora
```

### 3. Prueba r√°pida (pocas muestras)
```bash
python main.py --cataract_dir "data/Cataract COCO Segmentation" \
               --retinopathy_dir "data/Diabetic-Retinopathy COCO Segmentation" \
               --run_all \
               --max_samples 10
```

## ‚öôÔ∏è Configuraci√≥n Avanzada

### Finetuning Cl√°sico
```bash
python finetune_classic.py \
    --cataract_dir "data/Cataract COCO Segmentation" \
    --retinopathy_dir "data/Diabetic-Retinopathy COCO Segmentation" \
    --batch_size 2 \
    --num_epochs 10 \
    --learning_rate 1e-5 \
    --save_dir "checkpoints_classic"
```

### LoRA
```bash
python finetune_lora.py \
    --cataract_dir "data/Cataract COCO Segmentation" \
    --retinopathy_dir "data/Diabetic-Retinopathy COCO Segmentation" \
    --batch_size 4 \
    --num_epochs 15 \
    --learning_rate 1e-4 \
    --lora_r 16 \
    --lora_alpha 32 \
    --lora_dropout 0.1 \
    --save_dir "checkpoints_lora" \
    --merge_final
```

### QLoRA
```bash
python finetune_qlora.py \
    --cataract_dir "data/Cataract COCO Segmentation" \
    --retinopathy_dir "data/Diabetic-Retinopathy COCO Segmentation" \
    --batch_size 2 \
    --num_epochs 20 \
    --learning_rate 2e-4 \
    --lora_r 8 \
    --lora_alpha 16 \
    --lora_dropout 0.05 \
    --save_dir "checkpoints_qlora"
```

## üîç Inferencia y Evaluaci√≥n

### Inferencia en imagen individual
```bash
python inference.py \
    --model_type lora \
    --model_path "checkpoints_lora/sam2_lora_best" \
    --test_image "test_image.jpg"
```

### Evaluaci√≥n en dataset
```bash
python inference.py \
    --model_type qlora \
    --model_path "checkpoints_qlora/sam2_qlora_best" \
    --test_dataset "data/Cataract COCO Segmentation" \
    --dataset_split test \
    --max_samples 50
```

### Comparar m√∫ltiples modelos
```bash
# Crear archivo de configuraci√≥n (models_config.json)
echo '[
    {
        "name": "Classic",
        "type": "classic",
        "path": "checkpoints_classic/sam2_classic_best.pth"
    },
    {
        "name": "LoRA",
        "type": "lora", 
        "path": "checkpoints_lora/sam2_lora_best"
    },
    {
        "name": "QLoRA",
        "type": "qlora",
        "path": "checkpoints_qlora/sam2_qlora_best"
    }
]' > models_config.json

# Ejecutar comparaci√≥n
python inference.py \
    --compare_models models_config.json \
    --test_image "test_image.jpg"
```

## üìà Resultados y M√©tricas

Cada m√©todo genera:

1. **Checkpoints**: Modelos guardados durante el entrenamiento
2. **M√©tricas**: Gr√°ficas de loss e IoU por √©poca
3. **Logs**: Progreso detallado del entrenamiento

### Archivos generados:
- `checkpoints_*/`: Modelos entrenados
- `training_metrics_*.png`: Gr√°ficas de entrenamiento
- `evaluation_results_*.json`: Resultados de evaluaci√≥n
- `model_comparison.png`: Comparaci√≥n visual de modelos

## üîß Personalizaci√≥n

### Modificar hiperpar√°metros
Edita los valores por defecto en `main.py` o pasa argumentos personalizados:

```bash
python main.py \
    --classic_lr 5e-6 \
    --classic_epochs 20 \
    --lora_r 32 \
    --qlora_lr 3e-4 \
    # ... otros par√°metros
```

### Usar modelo diferente
```bash
python main.py \
    --model_name "facebook/sam-vit-large" \
    # ... otros argumentos
```

### A√±adir nuevos datasets
Modifica `utils.py` para incluir nuevos datasets en formato COCO.

## üí° Recomendaciones

### Por tipo de hardware:

**GPU >8GB VRAM:**
- Usar finetuning cl√°sico para mejor rendimiento
- Batch size 4-8

**GPU 4-8GB VRAM:**
- Usar LoRA
- Batch size 2-4

**GPU <4GB VRAM:**
- Usar QLoRA obligatoriamente
- Batch size 1-2

### Por objetivo:

**M√°ximo rendimiento:**
- Finetuning cl√°sico
- M√°s √©pocas
- Learning rate bajo

**Balance eficiencia/rendimiento:**
- LoRA con r=16-32
- Moderate learning rate

**M√°xima eficiencia:**
- QLoRA con r=8
- M√°s √©pocas para compensar

## üêõ Troubleshooting

### Error de memoria GPU
```bash
# Reducir batch size
--batch_size 1

# Usar QLoRA
--run_qlora

# Limitar muestras para testing
--max_samples 50
```

### Error de dependencias
```bash
# Reinstalar paquetes
pip install --upgrade torch transformers peft bitsandbytes
```

### Error en datasets
```bash
# Verificar estructura de directorios
ls "data/Cataract COCO Segmentation/train/"
ls "data/Diabetic-Retinopathy COCO Segmentation/train/"
```

## üìö Referencias

- [SAM2 Paper](https://arxiv.org/abs/2408.00714)
- [LoRA Paper](https://arxiv.org/abs/2106.09685)
- [QLoRA Paper](https://arxiv.org/abs/2305.14314)
- [Transformers Library](https://huggingface.co/docs/transformers)
- [PEFT Library](https://huggingface.co/docs/peft)

## ü§ù Contribuciones

Para contribuir:
1. Fork el repositorio
2. Crea una rama feature
3. Implementa mejoras
4. Env√≠a pull request

## üìÑ Licencia

Este proyecto est√° bajo licencia MIT. Ver archivo LICENSE para detalles.

---

¬°Listo para comenzar el finetuning de SAM2! üöÄ
